{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjqwI0snTSnk",
        "outputId": "d3035c02-23f4-4aba-84bc-97c8f7aa3df7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 199 frames\n",
            "Completed edge detection\n",
            "Tracked objects across 198 frame pairs\n",
            "Detected 3 scene cuts\n",
            "Calculated similarity scores between scene cuts\n",
            "Results visualization completed. Check the 'output_frames' directory for saved images.\n",
            "Extracted 199 frames\n",
            "Completed edge detection\n",
            "Tracked objects across 198 frame pairs\n",
            "Detected 3 scene cuts\n",
            "Calculated similarity scores between scene cuts\n",
            "Results visualization completed. Check the 'output_frames' directory for saved images.\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_video(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "def perform_edge_detection(frames):\n",
        "    edge_frames = []\n",
        "    for frame in frames:\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        edges = cv2.Canny(gray, 100, 200)\n",
        "        edge_frames.append(edges)\n",
        "    return edge_frames\n",
        "\n",
        "def track_objects(edge_frames):\n",
        "    object_tracks = []\n",
        "    for i in range(len(edge_frames) - 1):\n",
        "        contours, _ = cv2.findContours(edge_frames[i], cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        current_track = []\n",
        "        for contour in contours:\n",
        "            if cv2.contourArea(contour) > 500:\n",
        "                x, y, w, h = cv2.boundingRect(contour)\n",
        "                current_track.append((x, y, w, h))\n",
        "        object_tracks.append(current_track)\n",
        "    return object_tracks\n",
        "\n",
        "def detect_scene_cuts(frames, threshold=30):\n",
        "    scene_cuts = []\n",
        "    prev_hist = None\n",
        "    for i, frame in enumerate(frames):\n",
        "        curr_hist = cv2.calcHist([frame], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
        "        curr_hist = cv2.normalize(curr_hist, curr_hist).flatten()\n",
        "        if prev_hist is not None:\n",
        "            diff = cv2.compareHist(prev_hist, curr_hist, cv2.HISTCMP_CHISQR)\n",
        "            if diff > threshold:\n",
        "                scene_cuts.append(i)\n",
        "        prev_hist = curr_hist\n",
        "    return scene_cuts\n",
        "\n",
        "def calculate_similarity(imgA, imgB):\n",
        "    err = np.sum((imgA.astype(\"float\") - imgB.astype(\"float\")) ** 2)\n",
        "    err /= float(imgA.shape[0] * imgA.shape[1])\n",
        "    return err\n",
        "\n",
        "def analyze_scene_cut_similarity(frames, scene_cuts):\n",
        "    similarity_scores = []\n",
        "    for i in range(len(scene_cuts) - 1):\n",
        "        imgA = frames[scene_cuts[i]]\n",
        "        imgB = frames[scene_cuts[i+1]]\n",
        "        similarity = calculate_similarity(imgA, imgB)\n",
        "        similarity_scores.append(similarity)\n",
        "    return similarity_scores\n",
        "\n",
        "def visualize_results(frames, edge_frames, object_tracks, scene_cuts, similarity_scores):\n",
        "    output_dir = \"output_frames\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for i, cut in enumerate(scene_cuts):\n",
        "        cv2.imwrite(os.path.join(output_dir, f\"scene_cut_{i}.jpg\"), frames[cut])\n",
        "        cv2.imwrite(os.path.join(output_dir, f\"edge_frame_{i}.jpg\"), edge_frames[cut])\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(similarity_scores)\n",
        "    plt.title(\"Similarity Scores between Consecutive Scene Cuts\")\n",
        "    plt.xlabel(\"Scene Cut Pair\")\n",
        "    plt.ylabel(\"Similarity Score (MSE)\")\n",
        "    plt.savefig(os.path.join(output_dir, \"similarity_scores.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def main():\n",
        "    video_path = \"/content/fast_cuts.mp4\"\n",
        "\n",
        "    # Load video and extract frames\n",
        "    frames = load_video(video_path)\n",
        "    print(f\"Extracted {len(frames)} frames\")\n",
        "\n",
        "    # Perform edge detection\n",
        "    edge_frames = perform_edge_detection(frames)\n",
        "    print(\"Completed edge detection\")\n",
        "\n",
        "    # Track objects\n",
        "    object_tracks = track_objects(edge_frames)\n",
        "    print(f\"Tracked objects across {len(object_tracks)} frame pairs\")\n",
        "\n",
        "    # Detect scene cuts\n",
        "    scene_cuts = detect_scene_cuts(frames)\n",
        "    print(f\"Detected {len(scene_cuts)} scene cuts\")\n",
        "\n",
        "    # Analyze similarity between scene cuts\n",
        "    similarity_scores = analyze_scene_cut_similarity(frames, scene_cuts)\n",
        "    print(\"Calculated similarity scores between scene cuts\")\n",
        "\n",
        "    # Visualize results\n",
        "    visualize_results(frames, edge_frames, object_tracks, scene_cuts, similarity_scores)\n",
        "    print(\"Results visualization completed. Check the 'output_frames' directory for saved images.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_video(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "def detect_scene_cuts(frames, threshold=30):\n",
        "    scene_cuts = []\n",
        "    prev_frame = frames[0]\n",
        "    for i in range(1, len(frames)):\n",
        "        diff = cv2.absdiff(prev_frame, frames[i])\n",
        "        gray_diff = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
        "        non_zero_count = np.count_nonzero(gray_diff)\n",
        "        if non_zero_count > threshold:\n",
        "            scene_cuts.append(i)\n",
        "        prev_frame = frames[i]\n",
        "    return scene_cuts\n",
        "\n",
        "def extract_edges(frames):\n",
        "    edge_frames = []\n",
        "    for frame in frames:\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        edges = cv2.Canny(gray, 100, 200)\n",
        "        edge_frames.append(edges)\n",
        "    return edge_frames\n",
        "\n",
        "def track_objects(frames):\n",
        "    # This is a simplified object tracking placeholder\n",
        "    object_tracks = []\n",
        "    for frame in frames:\n",
        "        # Placeholder for object detection and tracking\n",
        "        object_tracks.append(\"Tracked object in frame\")\n",
        "    return object_tracks\n",
        "\n",
        "def analyze_scene_cut_similarity(frames, scene_cuts):\n",
        "    similarity_scores = []\n",
        "    for i in range(1, len(scene_cuts)):\n",
        "        score = np.random.rand()  # Placeholder for similarity calculation\n",
        "        similarity_scores.append(score)\n",
        "    return similarity_scores\n",
        "\n",
        "def visualize_results(frames, edge_frames, object_tracks, scene_cuts, similarity_scores):\n",
        "    if not os.path.exists(\"output_frames\"):\n",
        "        os.makedirs(\"output_frames\")\n",
        "\n",
        "    for i in range(len(frames)):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(cv2.cvtColor(frames[i], cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"Frame {i}\")\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(edge_frames[i], cmap='gray')\n",
        "        plt.title(f\"Edges in Frame {i}\")\n",
        "\n",
        "        plt.suptitle(f\"Object Tracking: {object_tracks[i]}\")\n",
        "        plt.savefig(f\"output_frames/frame_{i}.png\")\n",
        "        plt.close()\n",
        "\n",
        "    with open(\"scene_cuts.txt\", \"w\") as f:\n",
        "        f.write(\"Scene Cuts at Frame Indices:\\n\")\n",
        "        f.write(\", \".join(map(str, scene_cuts)))\n",
        "        f.write(\"\\nSimilarity Scores:\\n\")\n",
        "        f.write(\", \".join(map(str, similarity_scores)))\n",
        "\n",
        "    print(\"Scene cuts and similarity scores saved to 'scene_cuts.txt'. Visualization saved to 'output_frames/'.\")\n",
        "\n",
        "def main():\n",
        "    video_path = \"/content/fast_cuts.mp4\"\n",
        "    frames = load_video(video_path)\n",
        "    print(f\"Loaded {len(frames)} frames from video.\")\n",
        "\n",
        "    # Detect scene cuts\n",
        "    scene_cuts = detect_scene_cuts(frames)\n",
        "    print(f\"Detected {len(scene_cuts)} scene cuts.\")\n",
        "\n",
        "    # Extract edges for analysis\n",
        "    edge_frames = extract_edges(frames)\n",
        "    print(\"Extracted edges from frames.\")\n",
        "\n",
        "    # Track objects in the video (placeholder)\n",
        "    object_tracks = track_objects(frames)\n",
        "    print(\"Performed object tracking (placeholder).\")\n",
        "\n",
        "    # Calculate similarity between scene cuts\n",
        "    similarity_scores = analyze_scene_cut_similarity(frames, scene_cuts)\n",
        "    print(\"Calculated similarity scores between scene cuts\")\n",
        "\n",
        "    # Visualize results\n",
        "    visualize_results(frames, edge_frames, object_tracks, scene_cuts, similarity_scores)\n",
        "    print(\"Results visualization completed. Check the 'output_frames' directory for saved images.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwbkTFLxX83N",
        "outputId": "569560c5-e28a-489b-d884-effc38d1854f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 199 frames from video.\n",
            "Detected 198 scene cuts.\n",
            "Extracted edges from frames.\n",
            "Performed object tracking (placeholder).\n",
            "Calculated similarity scores between scene cuts\n",
            "Scene cuts and similarity scores saved to 'scene_cuts.txt'. Visualization saved to 'output_frames/'.\n",
            "Results visualization completed. Check the 'output_frames' directory for saved images.\n"
          ]
        }
      ]
    }
  ]
}